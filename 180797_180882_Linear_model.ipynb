{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "180797_180882_Linear_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goTgqMy_uOkQ",
        "outputId": "ea907278-2264-46ca-bfdd-bceae2ace6b3"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "import librosa.display\n",
        "from glob import glob\n",
        "from google.colab import drive\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "drive.mount(\"/content/gdrive\")\n",
        "\n",
        "sr=16000"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1jOv1dsuU6K",
        "outputId": "f5a3764a-6bb9-4fff-b9a3-c0824db04409"
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "import matplotlib.pyplot as plt\n",
        "tf.disable_v2_behavior()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcChTzRHu5Pk"
      },
      "source": [
        "def readDir(filename, Fs):\n",
        "    x , sr = librosa.load(filename , sr = Fs)\n",
        "    return x"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amuPrSLmvF1-"
      },
      "source": [
        "def readSpectrogram(infilename):\n",
        "    X = np.load(infilename)\n",
        "    return X"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UxotdIDvIeS"
      },
      "source": [
        "def zero_pad(x):\n",
        "    curr_len = np.size(x)\n",
        "    #Making the duration exactly 10 sec\n",
        "    if curr_len > 160000:\n",
        "        x = x[0:160000]\n",
        "    else:\n",
        "        x = np.pad(x, (0, 160000-curr_len), 'constant')\n",
        "    return x"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47mRo7D8vKwg"
      },
      "source": [
        "def calc_spec(x):\n",
        "    n_fft = 1024\n",
        "    hop_length = 512\n",
        "    win_length = 1024\n",
        "    X = np.abs(librosa.stft(x, n_fft = n_fft, hop_length = hop_length, win_length = win_length, window='hann', dtype = complex))\n",
        "    X = librosa.power_to_db(X**2,ref=np.max)\n",
        "    return X"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_UnBF9EvM2s"
      },
      "source": [
        "def label_framewise(arr):\n",
        "    #generate framewise one hot vectors for 3 classes(music,silence, speech)\n",
        "    hop_len = 512\n",
        "    win_length = 1024\n",
        "    Fs = 16000\n",
        "    no_of_events, x = np.shape(arr)\n",
        "    x = np.array([[0,1,0]]*313)\n",
        "\n",
        "    for i in range(no_of_events):\n",
        "      start_frame = round((arr[i][0]*Fs - win_length)/(hop_len)+1)\n",
        "      end_frame = round((arr[i][1]*Fs - win_length)/(hop_len)+1)\n",
        "      curr_class = arr[i][2]\n",
        "\n",
        "      if curr_class == 0: #music class\n",
        "        x[int(start_frame):int(end_frame)+1] = [1,0,0]\n",
        "      if curr_class == 2: #speech class\n",
        "        x[int(start_frame):int(end_frame)+1] = [0,0,1]\n",
        "      \n",
        "      \n",
        "    return x"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ck-M7zlYvQLO"
      },
      "source": [
        "def frame_to_time(m):\n",
        "    hop_len = 512\n",
        "    win_length = 1024\n",
        "    Fs = 16000\n",
        "    return ((m-1)*hop_len+win_length)/Fs"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-HDSM3EvSgp"
      },
      "source": [
        "def randomize(x, y):\n",
        "    \"\"\" Randomizes the order of data samples and their corresponding labels\"\"\"\n",
        "    permutation = np.random.permutation(y.shape[0])\n",
        "    shuffled_x = x[permutation, :]\n",
        "    shuffled_y = y[permutation]\n",
        "    return shuffled_x, shuffled_y\n",
        "\n",
        "def get_next_batch(x, y, start, end):\n",
        "    x_batch = x[start:end]\n",
        "    y_batch = y[start:end]\n",
        "    return x_batch, y_batch"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kbDmmtKvXPU"
      },
      "source": [
        "epochs = 10             # Total number of training epochs\n",
        "batch_size = 100        # Training batch size\n",
        "display_freq = 100      # Frequency of displaying the training results\n",
        "learning_rate = 0.001 "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQ2ahZxVvdvZ"
      },
      "source": [
        "def weight_variable(shape):\n",
        "    initer = tf.truncated_normal_initializer(stddev=0.01)\n",
        "    return tf.get_variable('W',dtype=tf.float32,shape=shape,initializer=initer)\n",
        "\n",
        "def bias_variable(shape):\n",
        "    initial = tf.constant(0., shape=shape, dtype=tf.float32)\n",
        "    return tf.get_variable('b',dtype=tf.float32,initializer=initial)\n",
        " "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMMEVIK5vsq3"
      },
      "source": [
        "Fs = 16000\n",
        "#folder containing all the wav files for training\n",
        "curr_folder = '/content/gdrive/My Drive/coding-1/wav_folder_final'\n",
        "path = os.path.join(curr_folder, '*.wav')\n",
        "folder = glob(path)\n",
        "\n",
        "file_count = 0\n",
        "for file in folder:\n",
        "    file_count = file_count + 1\n",
        "\n",
        "#csv file containing the classes and their onset and offset time\n",
        "csv_file = '/content/gdrive/My Drive/coding-1/wav_folder_final/labels.csv'\n",
        "df = pd.read_csv(csv_file)\n",
        "df = df.to_numpy()    \n",
        "\n",
        "file_list = os.listdir(curr_folder)\n",
        "file_name_list = df[:,0]\n",
        "\n",
        "feature_per_frame = 513\n",
        "frame_per_file = 313\n",
        "\n",
        "X_train = np.zeros((feature_per_frame,frame_per_file*file_count))\n",
        "Y_train = np.array([[0,1,0]]*frame_per_file*file_count)\n",
        "\n",
        "start = 0\n",
        "end = frame_per_file\n",
        "\n",
        "i = 0\n",
        "for file in folder:\n",
        "    x_data = readDir(file,Fs)\n",
        "    curr_len = np.size(x_data)\n",
        "    #data preprocessing\n",
        "    x_data = zero_pad(x_data)\n",
        "    \n",
        "    curr_spectrogram = calc_spec(x_data)\n",
        "    X_train[:, start:end] = curr_spectrogram\n",
        "\n",
        "    curr_file = (file_list[i])\n",
        "    curr_file = curr_file[0:len(curr_file)-4]\n",
        "    file_index = np.where(file_name_list == curr_file)\n",
        "    event_count = np.size(file_index)\n",
        "    timestamp_array = np.ones((event_count,3))\n",
        "    \n",
        "    for event in range(event_count):\n",
        "        curr_index = file_index[0][event]\n",
        "        onset = df[curr_index][1]\n",
        "        offset =  df[curr_index][2]\n",
        "        curr_class = df[curr_index][3]\n",
        "\n",
        "        timestamp_array[event][0] = onset\n",
        "        timestamp_array[event][1] = offset\n",
        "\n",
        "        if curr_class == 'music':\n",
        "            timestamp_array[event][2] = 0\n",
        "        if curr_class == 'speech':\n",
        "            timestamp_array[event][2] = 2\n",
        "\n",
        "    curr_label = label_framewise(timestamp_array)\n",
        "    Y_train[start:end,:] = curr_label\n",
        "\n",
        "    start = end\n",
        "    end = end + frame_per_file\n",
        "    i = i + 1"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRmt7dW_v5oK"
      },
      "source": [
        "#Splitting Data into training and validation\n",
        "X_train=np.transpose(X_train)\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(X_train, Y_train, train_size=0.8)\n",
        "img_size_flat = 513\n",
        "n_classes=3"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InfvNel8wLk7"
      },
      "source": [
        "# Create the graph for the linear model\n",
        "# Placeholders for inputs (x) and outputs(y)\n",
        "x = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='X')\n",
        "y = tf.placeholder(tf.float32, shape=[None, n_classes], name='Y')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CKeucSTwPTi"
      },
      "source": [
        "W = weight_variable(shape=[img_size_flat, n_classes])\n",
        "b = bias_variable(shape=[n_classes])\n",
        "\n",
        "output_logits = tf.matmul(x, W) + b"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B25-I6sNwR65",
        "outputId": "5cc10339-2d06-49a9-c75b-58d23f92d3d2"
      },
      "source": [
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=output_logits), name='loss')\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, name='Adam-op').minimize(loss)\n",
        "correct_prediction = tf.equal(tf.argmax(output_logits, 1), tf.argmax(y, 1), name='correct_pred')\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')\n",
        "\n",
        "# Model predictions\n",
        "cls_prediction = tf.argmax(output_logits, axis=1, name='predictions')\n",
        " "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCUsFPmHwVkA"
      },
      "source": [
        "# Creating the op for initializing all variables\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSGoMqM2wi0E",
        "outputId": "3cad0fdb-f916-4e5e-fcb0-97e6a76ee0ac"
      },
      "source": [
        "# Create an interactive session (to keep the session in the other cells)\n",
        "sess = tf.InteractiveSession()\n",
        "# Initialize all variables\n",
        "sess.run(init)\n",
        "# Number of training iterations in each epoch\n",
        "num_tr_iter = int(len(y_train) / batch_size)\n",
        "for epoch in range(epochs):\n",
        "    print('Training epoch: {}'.format(epoch + 1))\n",
        "    # Randomly shuffle the training data at the beginning of each epoch \n",
        "    x_train, y_train = randomize(x_train, y_train)\n",
        "    for iteration in range(num_tr_iter):\n",
        "        start = iteration * batch_size\n",
        "        end = (iteration + 1) * batch_size\n",
        "        x_batch, y_batch = get_next_batch(x_train, y_train, start, end)\n",
        "\n",
        "        # Run optimization op (backprop)\n",
        "        feed_dict_batch = {x: x_batch, y: y_batch}\n",
        "        # print(feed_dict_batch)\n",
        "        sess.run(optimizer, feed_dict=feed_dict_batch)\n",
        "\n",
        "        if iteration % display_freq == 0:\n",
        "            # Calculate and display the batch loss and accuracy\n",
        "            loss_batch, acc_batch = sess.run([loss, accuracy],\n",
        "                                             feed_dict=feed_dict_batch)\n",
        "\n",
        "            print(\"iter {0:3d}:\\t Loss={1:.2f},\\tTraining Accuracy={2:.01%}\".\n",
        "                  format(iteration, loss_batch, acc_batch))\n",
        "\n",
        "    # Run validation after every epoch\n",
        "    feed_dict_valid = {x: x_valid[:1000], y: y_valid[:1000]}\n",
        "    loss_valid, acc_valid = sess.run([loss, accuracy], feed_dict=feed_dict_valid)\n",
        "    print('---------------------------------------------------------')\n",
        "    print(\"Epoch: {0}, validation loss: {1:.2f}, validation accuracy: {2:.01%}\".\n",
        "          format(epoch + 1, loss_valid, acc_valid))\n",
        "    print('---------------------------------------------------------')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch: 1\n",
            "iter   0:\t Loss=11.98,\tTraining Accuracy=17.0%\n",
            "iter 100:\t Loss=0.58,\tTraining Accuracy=83.0%\n",
            "---------------------------------------------------------\n",
            "Epoch: 1, validation loss: 0.55, validation accuracy: 79.2%\n",
            "---------------------------------------------------------\n",
            "Training epoch: 2\n",
            "iter   0:\t Loss=0.62,\tTraining Accuracy=79.0%\n",
            "iter 100:\t Loss=0.65,\tTraining Accuracy=74.0%\n",
            "---------------------------------------------------------\n",
            "Epoch: 2, validation loss: 0.41, validation accuracy: 88.0%\n",
            "---------------------------------------------------------\n",
            "Training epoch: 3\n",
            "iter   0:\t Loss=0.34,\tTraining Accuracy=89.0%\n",
            "iter 100:\t Loss=0.25,\tTraining Accuracy=88.0%\n",
            "---------------------------------------------------------\n",
            "Epoch: 3, validation loss: 0.47, validation accuracy: 85.0%\n",
            "---------------------------------------------------------\n",
            "Training epoch: 4\n",
            "iter   0:\t Loss=0.30,\tTraining Accuracy=89.0%\n",
            "iter 100:\t Loss=0.57,\tTraining Accuracy=87.0%\n",
            "---------------------------------------------------------\n",
            "Epoch: 4, validation loss: 0.49, validation accuracy: 85.7%\n",
            "---------------------------------------------------------\n",
            "Training epoch: 5\n",
            "iter   0:\t Loss=0.55,\tTraining Accuracy=91.0%\n",
            "iter 100:\t Loss=2.63,\tTraining Accuracy=73.0%\n",
            "---------------------------------------------------------\n",
            "Epoch: 5, validation loss: 0.73, validation accuracy: 80.4%\n",
            "---------------------------------------------------------\n",
            "Training epoch: 6\n",
            "iter   0:\t Loss=0.47,\tTraining Accuracy=87.0%\n",
            "iter 100:\t Loss=0.80,\tTraining Accuracy=55.0%\n",
            "---------------------------------------------------------\n",
            "Epoch: 6, validation loss: 4.04, validation accuracy: 55.6%\n",
            "---------------------------------------------------------\n",
            "Training epoch: 7\n",
            "iter   0:\t Loss=1.30,\tTraining Accuracy=72.0%\n",
            "iter 100:\t Loss=2.25,\tTraining Accuracy=79.0%\n",
            "---------------------------------------------------------\n",
            "Epoch: 7, validation loss: 1.53, validation accuracy: 72.9%\n",
            "---------------------------------------------------------\n",
            "Training epoch: 8\n",
            "iter   0:\t Loss=1.02,\tTraining Accuracy=81.0%\n",
            "iter 100:\t Loss=0.36,\tTraining Accuracy=87.0%\n",
            "---------------------------------------------------------\n",
            "Epoch: 8, validation loss: 0.53, validation accuracy: 86.9%\n",
            "---------------------------------------------------------\n",
            "Training epoch: 9\n",
            "iter   0:\t Loss=0.13,\tTraining Accuracy=94.0%\n",
            "iter 100:\t Loss=0.72,\tTraining Accuracy=86.0%\n",
            "---------------------------------------------------------\n",
            "Epoch: 9, validation loss: 0.63, validation accuracy: 86.8%\n",
            "---------------------------------------------------------\n",
            "Training epoch: 10\n",
            "iter   0:\t Loss=0.33,\tTraining Accuracy=88.0%\n",
            "iter 100:\t Loss=0.37,\tTraining Accuracy=92.0%\n",
            "---------------------------------------------------------\n",
            "Epoch: 10, validation loss: 0.52, validation accuracy: 87.1%\n",
            "---------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3ljH_OKwlrp",
        "outputId": "9e301bbc-4348-4d10-d315-446190564d96"
      },
      "source": [
        "#Testing\n",
        "x_test, y_test = x_valid, y_valid\n",
        "feed_dict_test = {x: x_test[:1000], y: y_test[:1000]}\n",
        "loss_test, acc_test = sess.run([loss, accuracy], feed_dict=feed_dict_test)\n",
        "print('---------------------------------------------------------')\n",
        "print(\"Test loss: {0:.2f}, test accuracy: {1:.01%}\".format(loss_test, acc_test))\n",
        "print('---------------------------------------------------------')\n",
        " "
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------\n",
            "Test loss: 0.52, test accuracy: 87.1%\n",
            "---------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7b8v4QTXsRQ"
      },
      "source": [
        "XX=W.eval()\n",
        "bb=b.eval()\n",
        "np.save('/content/gdrive/My Drive/coding-1/W.npy',XX)\n",
        "np.save('/content/gdrive/My Drive/coding-1/b.npy',bb)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "re9rRn6oYg_0"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    }
  ]
}