{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "180797_180882_Neural_Network.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fQm81TKxQPm",
        "outputId": "1f3c9970-3da6-4ea4-94f9-5b1d4e9dc0c2"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "import librosa.display\n",
        "from glob import glob\n",
        "from google.colab import drive\n",
        "import os\n",
        "import pandas as pd\n",
        "drive.mount(\"/content/gdrive\")\n",
        "\n",
        "sr=16000"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kToRyD0SxemP"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.callbacks import EarlyStopping"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZCyqhQ8xqmI"
      },
      "source": [
        "def readDir(filename, Fs):\n",
        "    x , sr = librosa.load(filename , sr = Fs)\n",
        "    return x"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDta9_70xs-d"
      },
      "source": [
        "def readSpectrogram(infilename):\n",
        "    X = np.load(infilename)\n",
        "    return X"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_cG7447xu_6"
      },
      "source": [
        "def zero_pad(x):\n",
        "    curr_len = np.size(x)\n",
        "    #Making the duration exactly 10 sec\n",
        "    if curr_len > 160000:\n",
        "        x = x[0:160000]\n",
        "    else:\n",
        "        x = np.pad(x, (0, 160000-curr_len), 'constant')\n",
        "    return x"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCZbRcMfxxQb"
      },
      "source": [
        "def calc_spec(x):\n",
        "    n_fft = 1024\n",
        "    hop_length = 512\n",
        "    win_length = 1024\n",
        "    X = np.abs(librosa.stft(x, n_fft = n_fft, hop_length = hop_length, win_length = win_length, window='hann', dtype = complex))\n",
        "    X = librosa.power_to_db(X**2,ref=np.max)\n",
        "    return X"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BShWp9eixzON"
      },
      "source": [
        "def label_framewise(arr):\n",
        "    #generate framewise one hot vectors for 3 classes(music,silence, speech)\n",
        "    hop_len = 512\n",
        "    win_length = 1024\n",
        "    Fs = 16000\n",
        "    no_of_events, x = np.shape(arr)\n",
        "    x = np.array([[0,1,0]]*313)\n",
        "\n",
        "    for i in range(no_of_events):\n",
        "      start_frame = round((arr[i][0]*Fs - win_length)/(hop_len)+1)\n",
        "      end_frame = round((arr[i][1]*Fs - win_length)/(hop_len)+1)\n",
        "      curr_class = arr[i][2]\n",
        "\n",
        "      if curr_class == 0: #music class\n",
        "        x[int(start_frame):int(end_frame)+1] = [1,0,0]\n",
        "      if curr_class == 2: #speech class\n",
        "        x[int(start_frame):int(end_frame)+1] = [0,0,1]\n",
        "      \n",
        "      \n",
        "    return x"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBvvK-Aex1Ka"
      },
      "source": [
        "def frame_to_time(m):\n",
        "    hop_len = 512\n",
        "    win_length = 1024\n",
        "    Fs = 16000\n",
        "    return ((m-1)*hop_len+win_length)/Fs"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUTnkKmWx3fi"
      },
      "source": [
        "if __name__==\"__main__\":\n",
        "    \n",
        "    Fs = 16000\n",
        "    curr_folder = '/content/gdrive/My Drive/coding-1/wav_folder_final'\n",
        "    path = os.path.join(curr_folder, '*.wav')\n",
        "    folder = glob(path)\n",
        "\n",
        "    file_count = 0\n",
        "    for file in folder:\n",
        "        file_count = file_count + 1\n",
        "    \n",
        "    csv_file = '/content/gdrive/My Drive/coding-1/wav_folder_final/labels.csv'\n",
        "    df = pd.read_csv(csv_file)\n",
        "    df = df.to_numpy()    \n",
        "\n",
        "    file_list = os.listdir(curr_folder)\n",
        "    file_name_list = df[:,0]\n",
        "\n",
        "    feature_per_frame = 513\n",
        "    frame_per_file = 313\n",
        "\n",
        "    X_train = np.zeros((feature_per_frame,frame_per_file*file_count))\n",
        "    Y_train = np.array([[0,1,0]]*frame_per_file*file_count)\n",
        "    \n",
        "    start = 0\n",
        "    end = frame_per_file\n",
        "    \n",
        "    i = 0\n",
        "    for file in folder:\n",
        "        x_data = readDir(file,Fs)\n",
        "        curr_len = np.size(x_data)\n",
        "        #data preprocessing\n",
        "        x_data = zero_pad(x_data)\n",
        "        \n",
        "        curr_spectrogram = calc_spec(x_data)\n",
        "        X_train[:, start:end] = curr_spectrogram\n",
        "\n",
        "        curr_file = (file_list[i])\n",
        "        curr_file = curr_file[0:len(curr_file)-4]\n",
        "        file_index = np.where(file_name_list == curr_file)\n",
        "        event_count = np.size(file_index)\n",
        "        timestamp_array = np.ones((event_count,3))\n",
        "        \n",
        "        for event in range(event_count):\n",
        "            curr_index = file_index[0][event]\n",
        "            onset = df[curr_index][1]\n",
        "            offset =  df[curr_index][2]\n",
        "            curr_class = df[curr_index][3]\n",
        "\n",
        "            timestamp_array[event][0] = onset\n",
        "            timestamp_array[event][1] = offset\n",
        "\n",
        "            if curr_class == 'music':\n",
        "                timestamp_array[event][2] = 0\n",
        "            if curr_class == 'speech':\n",
        "                timestamp_array[event][2] = 2\n",
        "\n",
        "        curr_label = label_framewise(timestamp_array)\n",
        "        Y_train[start:end,:] = curr_label\n",
        "\n",
        "        start = end\n",
        "        end = end + frame_per_file\n",
        "        i = i + 1\n",
        "     "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sttFYLh3x5tW",
        "outputId": "7fff41e5-f51f-470f-df8d-4394015f411d"
      },
      "source": [
        "X_train=np.transpose(X_train)\n",
        "model = Sequential()\n",
        "model.add(Dense(16, input_shape=(X_train.shape[1],), activation='relu')) \n",
        "model.add(Dense(3, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 16)                8224      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,275\n",
            "Trainable params: 8,275\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M01-TGLCyjsP",
        "outputId": "d60bf315-b1e1-4f35-bdec-3821f8c7acc4"
      },
      "source": [
        "es = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=10, restore_best_weights=True)\n",
        "history = model.fit(X_train, Y_train, callbacks=[es], epochs=8000, batch_size=32, shuffle=True, validation_split=0.1,verbose=1)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8000\n",
            "441/441 [==============================] - 1s 2ms/step - loss: 2.8879 - accuracy: 0.7023 - val_loss: 1.7030 - val_accuracy: 0.7585\n",
            "Epoch 2/8000\n",
            "441/441 [==============================] - 1s 2ms/step - loss: 1.3145 - accuracy: 0.8077 - val_loss: 0.8773 - val_accuracy: 0.8543\n",
            "Epoch 3/8000\n",
            "441/441 [==============================] - 1s 2ms/step - loss: 0.9316 - accuracy: 0.8533 - val_loss: 0.3836 - val_accuracy: 0.9188\n",
            "Epoch 4/8000\n",
            "441/441 [==============================] - 1s 2ms/step - loss: 0.6099 - accuracy: 0.8648 - val_loss: 0.2579 - val_accuracy: 0.9323\n",
            "Epoch 5/8000\n",
            "441/441 [==============================] - 1s 2ms/step - loss: 0.4930 - accuracy: 0.8405 - val_loss: 0.2684 - val_accuracy: 0.9419\n",
            "Epoch 6/8000\n",
            "441/441 [==============================] - 1s 2ms/step - loss: 0.4361 - accuracy: 0.8558 - val_loss: 0.2651 - val_accuracy: 0.9470\n",
            "Epoch 7/8000\n",
            "441/441 [==============================] - 1s 2ms/step - loss: 0.3761 - accuracy: 0.8699 - val_loss: 0.2755 - val_accuracy: 0.9495\n",
            "Epoch 8/8000\n",
            "441/441 [==============================] - 1s 2ms/step - loss: 0.6867 - accuracy: 0.7330 - val_loss: 0.6509 - val_accuracy: 0.7227\n",
            "Epoch 9/8000\n",
            "441/441 [==============================] - 1s 2ms/step - loss: 0.5871 - accuracy: 0.7747 - val_loss: 0.5853 - val_accuracy: 0.7463\n",
            "Epoch 10/8000\n",
            "441/441 [==============================] - 1s 2ms/step - loss: 0.5381 - accuracy: 0.7914 - val_loss: 0.5215 - val_accuracy: 0.7879\n",
            "Epoch 11/8000\n",
            "441/441 [==============================] - 1s 2ms/step - loss: 0.5143 - accuracy: 0.8035 - val_loss: 0.5844 - val_accuracy: 0.7431\n",
            "Epoch 12/8000\n",
            "441/441 [==============================] - 1s 2ms/step - loss: 0.4944 - accuracy: 0.8129 - val_loss: 0.5066 - val_accuracy: 0.7725\n",
            "Epoch 13/8000\n",
            "441/441 [==============================] - 1s 2ms/step - loss: 0.4603 - accuracy: 0.8278 - val_loss: 0.4598 - val_accuracy: 0.8179\n",
            "Epoch 14/8000\n",
            "441/441 [==============================] - 1s 2ms/step - loss: 0.4481 - accuracy: 0.8307 - val_loss: 0.4142 - val_accuracy: 0.8307\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_slN33Vv2imn"
      },
      "source": [
        "#sample test data whose ground truth is known\n",
        "z=readSpectrogram('/content/gdrive/My Drive/coding-1/spectrogram_folder/test3.npy')\n",
        "array_spec=z"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfOuvnzl3d8u"
      },
      "source": [
        "z=10**(z/10)\n",
        "s=np.sum(z,axis=0)\n",
        "loc=np.where(s<0.001,0,1) # 1- Not Silent, 0- Silent"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zsp8dM033j1b",
        "outputId": "1cb46bff-d4c0-45e4-d45b-54cf9ab216eb"
      },
      "source": [
        "#TASK 1 - Event Detection\n",
        "start=0\n",
        "end=0\n",
        "list1=[]\n",
        "for i in range(0,len(loc)):\n",
        "  if i==0 and loc[i]==1:\n",
        "    start=0\n",
        "    end=0\n",
        "  elif loc[i]==0:\n",
        "    if(start != end):\n",
        "      list1.append([start, end])\n",
        "    start=loc[i]\n",
        "    end=start\n",
        "  elif loc[i]==1 and loc[i-1]==0:\n",
        "    start=i\n",
        "    end=start\n",
        "  elif loc[i]==1 and loc[i-1]==1:\n",
        "    end=end+1\n",
        "event_count = len(list1)\n",
        "arr2 = np.zeros((event_count,2))\n",
        "for i in range(event_count):\n",
        "  onset = frame_to_time(list1[i][0])\n",
        "  offset = frame_to_time(list1[i][1])\n",
        "\n",
        "  arr2[i][0] = onset\n",
        "  arr2[i][1] = offset\n",
        "print(list1)\n",
        "print(arr2)\n",
        "#arr2 contains the onset and offset times for every event in a 10 sec audio"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3, 118], [181, 302]]\n",
            "[[0.128 3.808]\n",
            " [5.824 9.696]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRXcwSq93nVR",
        "outputId": "9af8af76-dd3e-4634-b35e-7dfbbe41e196"
      },
      "source": [
        "#TASK 2 - Audio Classification\n",
        "pred=model.predict(np.transpose(array_spec))\n",
        "output=[]\n",
        "for interval in list1:\n",
        "  temp=pred[interval[0]:interval[1]]\n",
        "  temp=np.sum(temp,axis=0)\n",
        "  index=np.argmax(temp)\n",
        "  cat='music'\n",
        "  if index==1:\n",
        "    cat='silence'\n",
        "  if index==2:\n",
        "    cat='speech'\n",
        "  output.append([frame_to_time(interval[0]),frame_to_time(interval[1]),cat])\n",
        "print(output)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.128, 3.808, 'music'], [5.824, 9.696, 'music']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NM4mOYWy6obD",
        "outputId": "a2dd6761-97f5-4137-b4ae-eb30fe3d6b1b"
      },
      "source": [
        "model.save('/content/gdrive/My Drive/coding-1/')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/coding-1/assets\n"
          ]
        }
      ]
    }
  ]
}